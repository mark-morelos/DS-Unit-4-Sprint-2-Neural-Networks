{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_2.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6CeUvEmnS_v"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJKY_lGMnS_w"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:** Simple nodes that are highly interconnected elements and organized in layers that process information using dynamic state responses.\n",
        "- **Input Layer:** Provides network patterns that communicates to the hidden layer/s. Passive nodes that receives single value on input and duplicate the value to multiple outputs.\n",
        "- **Hidden Layer:** mathematical functions which intends to give intentional results.\n",
        "- **Output Layer:** link to hidden layers, hidden layers gives the connection to output layer and yields an output of prediction of the response variable.\n",
        "- **Activation Function:** can be found in nodes, it defines the output of the node that is provided an input/s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h14baNcRnS_w"
      },
      "source": [
        "Explain how back propagation works as if you were explaining it to a five year-old. Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7-A_buwnS_w"
      },
      "source": [
        "Backpropagation is for computers to remember their mistakes and not to do it again, or do better next time. While these computers are being used, they keep getting better at the thing we ask them to do. Then when they all get better on these tasks, if they put these things they learned altogether, they can now perform a more difficult job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbWk4hpvnTBH"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. In a simple prediction describe the process of making a prediction. How do you go from inputs to predicted output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oxFG-renTBI"
      },
      "source": [
        "Single perceptron is an arrangement of one input layer of neurons feeding forward to one output layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3p8mLrXnTBI"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using Tensorflow Keras. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSxjKssUnTBI"
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
        "                     np.linspace(-3, 3, 50))\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j34M_v5nTBJ"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. You model should have 1 dense layer with a single neuron and a sigmoid activation function. Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30u7jbGBv9lC",
        "outputId": "e64f1217-30f9-4348-d21f-cca6e3b1f721",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(units=1, input_dim=2, activation='sigmoid'))\n",
        "\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "h1 = model1.fit(X, y, epochs=5)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9556 - accuracy: 0.4467\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9521 - accuracy: 0.4467\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9488 - accuracy: 0.4467\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9452 - accuracy: 0.4500\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9418 - accuracy: 0.4500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A95aaUTBwsfw",
        "outputId": "6617f2ec-f14e-452b-b89e-917d0eb068e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = model1.evaluate(X, y)\n",
        "print(f\"{model1.metrics_names[1]}: {scores[1]*100}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9397 - accuracy: 0.4500\n",
            "accuracy: 44.999998807907104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goL8a8bBnTBL"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron using. Here are some architecture suggestions: \n",
        "- 2 Hidden Layers\n",
        "- 5-32 Neurons in the Hidden Layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the Callback function below into your model\n",
        "\n",
        "Your model should be called `model2` and make sure to save the results of your fit statement to a variable called `h2`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFrCZP16nTBL"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > .99999):   \n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvfVhJYayl_G",
        "outputId": "c8e1808a-27fd-456b-ad64-62f2b93a7dfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model2 = Sequential([\n",
        "  Dense(512, activation='relu', input_dim=2),\n",
        "  Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# compile model\n",
        "model2.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fit on training / evaluate on validation set\n",
        "h2 = model2.fit(X, y,\n",
        "          epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2.1503 - accuracy: 0.4625 - val_loss: 1.9277 - val_accuracy: 0.7833\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8188 - accuracy: 0.7583 - val_loss: 1.6164 - val_accuracy: 0.9000\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5132 - accuracy: 0.9042 - val_loss: 1.3386 - val_accuracy: 0.9333\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2449 - accuracy: 0.9333 - val_loss: 1.1009 - val_accuracy: 0.9333\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0184 - accuracy: 0.9250 - val_loss: 0.9158 - val_accuracy: 0.9000\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8393 - accuracy: 0.9208 - val_loss: 0.7782 - val_accuracy: 0.8500\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7065 - accuracy: 0.9167 - val_loss: 0.6736 - val_accuracy: 0.8667\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.9208 - val_loss: 0.5960 - val_accuracy: 0.8667\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.9167 - val_loss: 0.5402 - val_accuracy: 0.8667\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.9208 - val_loss: 0.4934 - val_accuracy: 0.8833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ET278414LAT",
        "outputId": "c9b11c3c-5948-4bd9-c27d-df113ae9c9ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# evaluate on test data\n",
        "model2.evaluate(X, y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.9233\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.470326691865921, 0.9233333468437195]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdaEmtk4nTBL"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrmT6aSRnTBM",
        "outputId": "135f423e-9d02-4794-e04c-4c010b4292e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "# Do Not change anything in this cell\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "# create a mesh to plot in\n",
        "x_min, x_max = X[:, 0].min() - .2, X[:, 0].max() + .2\n",
        "y_min, y_max = X[:, 1].min() - .2, X[:, 1].max() + .2\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c2f9b7afbd9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/decision_regions.py\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[0;34m(X, y, clf, feature_index, filler_feature_values, filler_feature_ranges, ax, X_highlight, res, legend, hide_spines, markers, colors, scatter_kwargs, contourf_kwargs, scatter_highlight_kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mX_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiller_feature_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;31m# Plot decisoin region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m# Make sure contourf_kwargs has backwards compatible defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3732480 into shape (432,864)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjRq8I62nTBM"
      },
      "source": [
        "Why does the Perceptron (`model1`) only achieve ~70% accuracy? What is the architectural property of the Multi-Layer Perceptron that allows it more accurately learn the relationship between X and y? \n",
        "\n",
        "Why might this property be useful in more complex data such as images?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oIN7dcJnTBM"
      },
      "source": [
        "# Your Answer Here - Change the Cell to Markdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVRL8sqXnTBM"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
        "Use the Heart Disease Dataset (binary classification)\n",
        "Use an appropriate loss function for a binary classification task\n",
        "Use an appropriate activation function on the final layer of your network.\n",
        "Train your model using verbose output for ease of grading.\n",
        "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
        "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "h_bOCq7VnTBM",
        "outputId": "3eadee11-59b1-4b35-ef44-41528463a432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>256</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>149</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>140</td>\n",
              "      <td>313</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>133</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>299</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>134</td>\n",
              "      <td>201</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>303</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "50    51    0   2       130   256    0  ...      0      0.5      2   0     2       1\n",
              "112   64    0   2       140   313    0  ...      0      0.2      2   0     3       1\n",
              "253   67    1   0       100   299    0  ...      1      0.9      1   2     2       0\n",
              "55    52    1   1       134   201    0  ...      0      0.8      2   1     2       1\n",
              "59    57    0   0       128   303    0  ...      0      0.0      2   1     2       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AxwXgABnTBO"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import normalize\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam, Adagrad, SGD, Ftrl, RMSprop"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYCXKHEM4tu-"
      },
      "source": [
        "target = \"target\"\n",
        "features = [column for column in df.columns if column != \"target\"]\n",
        "\n",
        "y = df[target].values\n",
        "X = df[features].values"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBUn8oZm5I-N"
      },
      "source": [
        "normal_X = normalize(X)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZMfMcgh5QmA"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(normal_X, y, train_size= 0.8, test_size= 0.2)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0JGsIoc5SR8",
        "outputId": "ea52fd75-4c93-4ce2-86cf-cd07fa7d2673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(64, activation= \"sigmoid\", input_shape= (13,)),\n",
        "    Dense(32, activation= \"relu\"),\n",
        "    Dense(16, activation= \"sigmoid\"),\n",
        "    Dense(8, activation= \"relu\"),\n",
        "    Dense(1, activation= \"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=100,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.2649 - accuracy: 0.4504 - val_loss: 0.2556 - val_accuracy: 0.4754\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2560 - accuracy: 0.4504 - val_loss: 0.2519 - val_accuracy: 0.4754\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2512 - accuracy: 0.4504 - val_loss: 0.2501 - val_accuracy: 0.4754\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2499 - accuracy: 0.5248 - val_loss: 0.2499 - val_accuracy: 0.5246\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2496 - accuracy: 0.5496 - val_loss: 0.2498 - val_accuracy: 0.5246\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2494 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2493 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2492 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2491 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2491 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2489 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2489 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2488 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2487 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2486 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2486 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2485 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2485 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2485 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2484 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2484 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2483 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2483 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2483 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2483 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2482 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2482 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2482 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2482 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2482 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2481 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2481 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2481 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2481 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2480 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2480 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2480 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2480 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2480 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2479 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2479 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzjZ2v0J5epf"
      },
      "source": [
        "# Function to create model\n",
        "\n",
        "def create_model(units=32):\n",
        "    \n",
        "    # create model\n",
        "    model = Sequential([\n",
        "    Dense(64, activation= \"sigmoid\", input_shape= (13,)),\n",
        "    Dense(32, activation= \"relu\"),\n",
        "    Dense(16, activation= \"sigmoid\"),\n",
        "    Dense(8, activation= \"relu\"),\n",
        "    Dense(1, activation= \"sigmoid\")\n",
        "    ])\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', \n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT0D5Dnh5kPP",
        "outputId": "1fee6edc-3be2-48b9-9713-24f80801f02d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
        "\n",
        "# define grid search parameters\n",
        "param_grid = {'batch_size': [10, 20, 40], \n",
        "              'epochs': [20, 30, 50]}\n",
        "\n",
        "# create grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "\n",
        "# report results\n",
        "grid_result = grid.fit(X_train, y_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.5233\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.5233\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5233\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.5233\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6be582f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.6531\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.5026\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5337\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.5337\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.5337\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5337\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5337\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5337\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5337\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5337\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.5337\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5337\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5337\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5337\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.6122\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.4175\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5722\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.5722\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.5722\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.5722\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.5722\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2454 - accuracy: 0.5722\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.4583\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.4639\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5567\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.5567\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.5567\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.5567\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.5567\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.5567\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.5208\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.5515\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5619\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5619\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.5619\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.5619\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5619\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5619\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5619\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5619\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5619\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.5619\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.5000\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.4611\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.5233\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5233\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.5233\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.5233\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4301\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.5233\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5233\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.5233\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5233\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.5233\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.5233\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5233\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.6531\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2599 - accuracy: 0.4663\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.4715\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.5337\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.5337\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.5337\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.5337\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5337\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5337\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.6122\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.5155\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.5722\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.5722\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.5722\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.5722\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.5722\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.5722\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.5722\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.5722\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5722\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5722\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.5722\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5722\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.5722\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.5722\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.5722\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.5722\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.5722\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.4583\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.4433\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.5361\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.5567\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.5567\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.5567\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.5567\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.5567\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.5567\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.5567\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.5567\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.5567\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.5567\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.5567\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.5567\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5567\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.5208\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.4381\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5619\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5619\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.5619\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5619\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5619\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.5619\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.5619\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.5619\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5619\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5619\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5619\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5619\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5619\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5619\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.5619\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.5619\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.5619\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.5619\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.5000\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.4767\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.4767\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4715\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4663\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.4819\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.5233\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.6531\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.4663\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.5389\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5337\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.5337\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.5337\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5337\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5337\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.4767\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5337\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.5337\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5337\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5337\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5337\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.5337\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.5337\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.5337\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.5337\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.4974\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.5337\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.5337\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.5337\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.5337\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2477 - accuracy: 0.5337\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.6122\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5722\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.5722\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.5722\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.5722\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.5722\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.5722\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.5722\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.5722\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.5722\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.5722\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.5722\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.5722\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.5722\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.5722\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.5722\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.5722\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.5722\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.5722\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.5722\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.5722\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.4583\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5567\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.5567\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.5567\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.5567\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.5567\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.5567\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.5567\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.5567\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5567\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.5567\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.5567\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.5567\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.5567\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.5567\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.5567\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5567\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.5567\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.5567\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.5567\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.5567\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.5567\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.5567\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5567\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.5567\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5208\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5619\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5619\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5619\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.5619\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5619\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5619\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5619\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5619\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.5619\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5619\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.5619\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.5619\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5619\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.5619\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.5619\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.5619\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5619\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.5619\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.5619\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.5619\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.5619\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.5619\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.5619\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.5619\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.5619\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.5619\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.5619\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.5000\n",
            "Epoch 1/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.5233\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.5233\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.5233\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.6531\n",
            "Epoch 1/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2558 - accuracy: 0.5337\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.5337\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5337\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5337\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.5337\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5337\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.5337\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.6122\n",
            "Epoch 1/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2524 - accuracy: 0.5722\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5722\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.5722\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.5722\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2453 - accuracy: 0.5722\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.4583\n",
            "Epoch 1/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2557 - accuracy: 0.5567\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.5567\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.5567\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.5567\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.5567\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6bcf6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.5208\n",
            "Epoch 1/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.5619\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5619\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5619\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5619\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5619\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c7322f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.5000\n",
            "Epoch 1/30\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2657 - accuracy: 0.4000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0049s). Check your callbacks.\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.4767\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.5233\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.5233\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2499 - accuracy: 0.5233\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.5440\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.5233\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.5233\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5233\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5233\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5233\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5233\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5233\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6dae3bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.6531\n",
            "Epoch 1/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2582 - accuracy: 0.4663\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2544 - accuracy: 0.4663\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.4663\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.4715\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c71760378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.2390 - accuracy: 0.7000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2440 - accuracy: 0.6122\n",
            "Epoch 1/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5412\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.5722\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2454 - accuracy: 0.5722\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.5722\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.5722\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.5722\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.5722\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.5722\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2442 - accuracy: 0.5722\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.5722\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6d20dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2594 - accuracy: 0.4583\n",
            "Epoch 1/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.5567\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6d20dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.2421 - accuracy: 0.6000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0051s). Check your callbacks.\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.5208\n",
            "Epoch 1/30\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2504 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0071s). Check your callbacks.\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.5412\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2457 - accuracy: 0.5619\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.5619\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5619\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5619\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5619\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.5619\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5619\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.5619\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.5619\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c754d6a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.5000\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.5233\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.5233\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.5233\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.5233\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5233\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5233\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.5233\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.5233\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.5233\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5233\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.5233\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5233\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5233\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5233\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5233\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5233\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5233\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5233\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5233\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5233\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5233\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5233\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c68c4d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.2407 - accuracy: 0.6500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0037s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2411 - accuracy: 0.6531\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2644 - accuracy: 0.4663\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.5337\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5337\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5337\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.5337\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.5337\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5337\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5337\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5337\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.5337\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.5337\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2483 - accuracy: 0.5337\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.5337\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c729c6268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.2408 - accuracy: 0.7000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0079s). Check your callbacks.\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2447 - accuracy: 0.6122\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.5722\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2454 - accuracy: 0.5722\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5722\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.5722\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.5722\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.5722\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.5722\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.5722\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.5722\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.5722\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2444 - accuracy: 0.5722\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2443 - accuracy: 0.5722\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.5722\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.5722\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.5722\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.5722\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2438 - accuracy: 0.5722\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.5722\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.5722\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.5722\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.5722\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.5722\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2436 - accuracy: 0.5722\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.5722\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.5722\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.5722\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c69d882f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2592 - accuracy: 0.4583\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5567\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.5567\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.5567\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5567\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5567\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5567\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5567\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5567\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5567\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.5567\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.5567\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.5567\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5567\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5567\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2457 - accuracy: 0.5567\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5567\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2454 - accuracy: 0.5567\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.5567\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2456 - accuracy: 0.5567\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6bc7dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.5208\n",
            "Epoch 1/50\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2662 - accuracy: 0.4500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_train_batch_end` time: 0.0057s). Check your callbacks.\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.4381\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2514 - accuracy: 0.4381\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5619\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.5619\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5619\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5619\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5619\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5619\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.5619\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.5619\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.5619\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5619\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5619\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.5619\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.5619\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2456 - accuracy: 0.5619\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.5619\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.5619\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.5619\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.5619\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.5619\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.5619\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6bc7dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2538 - accuracy: 0.5000\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2527 - accuracy: 0.5233\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.5233\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.5233\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c65219c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2427 - accuracy: 0.6531\n",
            "Epoch 1/20\n",
            "1/5 [=====>........................] - ETA: 0s - loss: 0.2875 - accuracy: 0.4750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0047s vs `on_train_batch_end` time: 0.0194s). Check your callbacks.\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2613 - accuracy: 0.5337\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2532 - accuracy: 0.5337\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.5337\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5337\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.5337\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5337\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.5337\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2485 - accuracy: 0.5337\n",
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c755bc8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2436 - accuracy: 0.6122\n",
            "Epoch 1/20\n",
            "1/5 [=====>........................] - ETA: 0s - loss: 0.2818 - accuracy: 0.4500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0037s vs `on_train_batch_end` time: 0.0107s). Check your callbacks.\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2482 - accuracy: 0.5722\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.5722\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c65304bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2617 - accuracy: 0.4583\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.5567\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.5567\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.5567\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c71760158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.5208\n",
            "Epoch 1/20\n",
            "1/5 [=====>........................] - ETA: 0s - loss: 0.2799 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0038s vs `on_train_batch_end` time: 0.0067s). Check your callbacks.\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2927 - accuracy: 0.4381\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2757 - accuracy: 0.4381\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.4381\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2573 - accuracy: 0.4381\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2533 - accuracy: 0.4381\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.4381\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.5515\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2485 - accuracy: 0.5619\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.5619\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.5619\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5619\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5619\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5619\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5619\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6c949d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2530 - accuracy: 0.5000\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2512 - accuracy: 0.5233\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2512 - accuracy: 0.4249\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.4663\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.5233\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.5233\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.5233\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2500 - accuracy: 0.5233\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2499 - accuracy: 0.5233\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.5233\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.5233\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.5233\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2498 - accuracy: 0.5233\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5233\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5233\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5233\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c768b1e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2436 - accuracy: 0.6531\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2503 - accuracy: 0.4663\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.5026\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5337\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5337\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c768b1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2435 - accuracy: 0.6122\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.4278\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.4278\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.4278\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.4278\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.4278\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2591 - accuracy: 0.4278\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.4278\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.4278\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.4794\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.5722\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.5722\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2472 - accuracy: 0.5722\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2470 - accuracy: 0.5722\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.5722\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5722\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5722\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5722\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5722\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.5722\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.5722\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.5722\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2454 - accuracy: 0.5722\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2454 - accuracy: 0.5722\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.5722\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.5722\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.5722\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c65219bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.4583\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.5567\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2514 - accuracy: 0.5567\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.5567\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.5567\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5567\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5567\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5567\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2462 - accuracy: 0.5567\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2462 - accuracy: 0.5567\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5567\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c755b87b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5208\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.4381\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3032 - accuracy: 0.4381\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2821 - accuracy: 0.4381\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2686 - accuracy: 0.4381\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2579 - accuracy: 0.4381\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.4381\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.4381\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2542 - accuracy: 0.4381\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.4381\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2528 - accuracy: 0.4381\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2523 - accuracy: 0.4381\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2518 - accuracy: 0.4381\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.4381\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.4381\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.4381\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.4381\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.5412\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.5619\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5619\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5619\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5619\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2486 - accuracy: 0.5619\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.5619\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2481 - accuracy: 0.5619\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2481 - accuracy: 0.5619\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.5619\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.5619\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.5619\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.5619\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.5619\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6bb07598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5000\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2524 - accuracy: 0.5233\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.5233\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.5233\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.5233\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.5233\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5233\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2491 - accuracy: 0.5233\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2491 - accuracy: 0.5233\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2491 - accuracy: 0.5233\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2491 - accuracy: 0.5233\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.5233\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5233\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2490 - accuracy: 0.5233\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5233\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5233\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.5233\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5233\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6e348d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2426 - accuracy: 0.6531\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.4663\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.5233\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.5337\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.5337\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.5337\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5337\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5337\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2485 - accuracy: 0.5337\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.5337\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.5337\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.5337\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.5337\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2485 - accuracy: 0.5337\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.5337\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.5337\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6bfb5c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.6122\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.5722\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.5722\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.5722\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.5722\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.5722\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.5722\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6bfb5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.4583\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.5567\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.5567\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.5567\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.5567\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.5567\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2480 - accuracy: 0.5567\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.5567\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.5567\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5567\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.5567\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5567\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5567\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6b9e07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.5208\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2644 - accuracy: 0.5619\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.5619\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.5619\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.5619\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.5619\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5619\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5619\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.5619\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2462 - accuracy: 0.5619\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2461 - accuracy: 0.5619\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c67343730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2630 - accuracy: 0.4250WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0050s). Check your callbacks.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2537 - accuracy: 0.5000\n",
            "Epoch 1/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.5496\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.5496\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.2480 - accuracy: 0.5496\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2482 - accuracy: 0.5496\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.5496\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.5496\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.5496\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.5496\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.5496\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.5496\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.5496\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.5496\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2483 - accuracy: 0.5496\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.5496\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2483 - accuracy: 0.5496\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.5496\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2474 - accuracy: 0.5496\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.5496\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.5496\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.5496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKsYCDc85qeE",
        "outputId": "3b5ff5a9-1c38-4d2c-f8f0-4c6002eb1c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "grid.best_params_"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 10, 'epochs': 20}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1gmtJvd8HfT",
        "outputId": "bbe5f4b1-4be9-47a8-8a36-793188b2b373",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "optimizers = [\"Adagrad\", \"sgd\"]\n",
        "\n",
        "for optimizer in optimizers:\n",
        "    \n",
        "    print(f\"Optimizer: {optimizer}\")\n",
        "    \n",
        "    model = create_model(optimizer)\n",
        "    \n",
        "    model.fit(X_train, y_train, epochs= 50, batch_size= 10, \n",
        "              validation_data= (X_test, y_test))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer: Adagrad\n",
            "Epoch 1/50\n",
            "16/25 [==================>...........] - ETA: 0s - loss: 0.3074 - accuracy: 0.5375WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2c6bab9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.2937 - accuracy: 0.5496 - val_loss: 0.2822 - val_accuracy: 0.5246\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2613 - accuracy: 0.5496 - val_loss: 0.2558 - val_accuracy: 0.5246\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.5496 - val_loss: 0.2505 - val_accuracy: 0.5246\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2475 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2498 - val_accuracy: 0.5246\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.5496 - val_loss: 0.2500 - val_accuracy: 0.5246\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2499 - val_accuracy: 0.5246\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.5496 - val_loss: 0.2493 - val_accuracy: 0.5246\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5496 - val_loss: 0.2502 - val_accuracy: 0.5246\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.5496 - val_loss: 0.2501 - val_accuracy: 0.5246\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5496 - val_loss: 0.2499 - val_accuracy: 0.5246\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.5496 - val_loss: 0.2503 - val_accuracy: 0.5246\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.5496 - val_loss: 0.2491 - val_accuracy: 0.5246\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5496 - val_loss: 0.2499 - val_accuracy: 0.5246\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.5496 - val_loss: 0.2492 - val_accuracy: 0.5246\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.5496 - val_loss: 0.2491 - val_accuracy: 0.5246\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5496 - val_loss: 0.2492 - val_accuracy: 0.5246\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2493 - val_accuracy: 0.5246\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.5496 - val_loss: 0.2503 - val_accuracy: 0.5246\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5496 - val_loss: 0.2493 - val_accuracy: 0.5246\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.5496 - val_loss: 0.2489 - val_accuracy: 0.5246\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2475 - accuracy: 0.5496 - val_loss: 0.2493 - val_accuracy: 0.5246\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.5496 - val_loss: 0.2502 - val_accuracy: 0.5246\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.5496 - val_loss: 0.2488 - val_accuracy: 0.5246\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5496 - val_loss: 0.2488 - val_accuracy: 0.5246\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5496 - val_loss: 0.2490 - val_accuracy: 0.5246\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2492 - val_accuracy: 0.5246\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.5496 - val_loss: 0.2511 - val_accuracy: 0.5246\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2471 - accuracy: 0.5496 - val_loss: 0.2487 - val_accuracy: 0.5246\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.5496 - val_loss: 0.2492 - val_accuracy: 0.5246\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.5496 - val_loss: 0.2493 - val_accuracy: 0.5246\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.5496 - val_loss: 0.2502 - val_accuracy: 0.5246\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.5496 - val_loss: 0.2502 - val_accuracy: 0.5246\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5496 - val_loss: 0.2485 - val_accuracy: 0.5246\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5496 - val_loss: 0.2494 - val_accuracy: 0.5246\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5496 - val_loss: 0.2488 - val_accuracy: 0.5246\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.5496 - val_loss: 0.2487 - val_accuracy: 0.5246\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.5496 - val_loss: 0.2488 - val_accuracy: 0.5246\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2454 - accuracy: 0.5496 - val_loss: 0.2492 - val_accuracy: 0.5246\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.5496 - val_loss: 0.2491 - val_accuracy: 0.5246\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5496 - val_loss: 0.2492 - val_accuracy: 0.5246\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.5496 - val_loss: 0.2500 - val_accuracy: 0.5246\n",
            "Optimizer: sgd\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.2484 - accuracy: 0.5579 - val_loss: 0.2498 - val_accuracy: 0.5246\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2500 - val_accuracy: 0.5246\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2502 - val_accuracy: 0.5246\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2504 - val_accuracy: 0.5246\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.5496 - val_loss: 0.2498 - val_accuracy: 0.5246\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2502 - val_accuracy: 0.5246\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.5496 - val_loss: 0.2500 - val_accuracy: 0.5246\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2483 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.5496 - val_loss: 0.2503 - val_accuracy: 0.5246\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.5496 - val_loss: 0.2507 - val_accuracy: 0.5246\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2504 - val_accuracy: 0.5246\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2498 - val_accuracy: 0.5246\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.5496 - val_loss: 0.2501 - val_accuracy: 0.5246\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.5496 - val_loss: 0.2502 - val_accuracy: 0.5246\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.5496 - val_loss: 0.2500 - val_accuracy: 0.5246\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.5496 - val_loss: 0.2502 - val_accuracy: 0.5246\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.5496 - val_loss: 0.2500 - val_accuracy: 0.5246\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2498 - val_accuracy: 0.5246\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2474 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2475 - accuracy: 0.5496 - val_loss: 0.2498 - val_accuracy: 0.5246\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5496 - val_loss: 0.2501 - val_accuracy: 0.5246\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.5496 - val_loss: 0.2502 - val_accuracy: 0.5246\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5496 - val_loss: 0.2498 - val_accuracy: 0.5246\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2471 - accuracy: 0.5496 - val_loss: 0.2498 - val_accuracy: 0.5246\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5496 - val_loss: 0.2495 - val_accuracy: 0.5246\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.5496 - val_loss: 0.2501 - val_accuracy: 0.5246\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.5496 - val_loss: 0.2493 - val_accuracy: 0.5246\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2475 - accuracy: 0.5496 - val_loss: 0.2501 - val_accuracy: 0.5246\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2470 - accuracy: 0.5496 - val_loss: 0.2499 - val_accuracy: 0.5246\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2474 - accuracy: 0.5496 - val_loss: 0.2501 - val_accuracy: 0.5246\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5496 - val_loss: 0.2496 - val_accuracy: 0.5246\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2470 - accuracy: 0.5496 - val_loss: 0.2493 - val_accuracy: 0.5246\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.5496 - val_loss: 0.2493 - val_accuracy: 0.5246\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.5496 - val_loss: 0.2491 - val_accuracy: 0.5246\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.5496 - val_loss: 0.2497 - val_accuracy: 0.5246\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.5496 - val_loss: 0.2491 - val_accuracy: 0.5246\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.5496 - val_loss: 0.2500 - val_accuracy: 0.5246\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.5496 - val_loss: 0.2489 - val_accuracy: 0.5246\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.5496 - val_loss: 0.2492 - val_accuracy: 0.5246\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5496 - val_loss: 0.2501 - val_accuracy: 0.5246\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.5496 - val_loss: 0.2490 - val_accuracy: 0.5246\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.5496 - val_loss: 0.2493 - val_accuracy: 0.5246\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
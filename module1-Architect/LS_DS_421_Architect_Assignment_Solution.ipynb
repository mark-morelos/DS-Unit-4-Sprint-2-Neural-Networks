{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_421_Architect_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObyHCH8HvHSf"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# *Data Science Unit 4 Sprint 2 Assignment 1*\n",
        "\n",
        "Use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Please build a baseline classification model then run a few experiments with different optimizers and learning rates. \n",
        "\n",
        "*Don't forgot to switch to GPU on Colab!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Tc3ovEyQ9b"
      },
      "source": [
        "## Load Your Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkU0pAYCvU8o",
        "outputId": "db18ef9e-6165-4494-fa40-c8eb3f0c4566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "\n",
        "data = np.load('quickdraw10.npz')\n",
        "X = data['arr_0']\n",
        "y = data['arr_1']\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 784)\n",
            "(100000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8qsDqdqvHDd"
      },
      "source": [
        "class_names = ['apple',\n",
        " 'anvil',\n",
        " 'airplane',\n",
        " 'banana',\n",
        " 'The Eiffel Tower',\n",
        " 'The Mona Lisa',\n",
        " 'The Great Wall of China',\n",
        " 'alarm clock',\n",
        " 'ant',\n",
        " 'asparagus']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owbm1EbxvA5A",
        "outputId": "64fe1123-690e-41a2-d8b4-1bd60f901819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,5))\n",
        "start = 0\n",
        "\n",
        "for num, name in enumerate(class_names):\n",
        "    plt.subplot(2,5, num+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X[start].reshape(28,28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(name)\n",
        "    start += 10000\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4wvg4GYLKmH",
        "outputId": "815b797e-4922-48d4-b6e6-8928b23fc4c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y[9990:10110]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c97_M1WNvTNY"
      },
      "source": [
        "# Need this line to randomly shuffle both the X & y at the same time.\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "X, y = shuffle(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9n9t182LkYY",
        "outputId": "04924419-f634-43f3-d302-62e2e4405429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y[9990:10110]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 7, 1, 7, 0, 6, 0, 1, 6, 2, 3, 8, 3, 2, 9, 4, 3, 1, 1, 0, 0, 1,\n",
              "       4, 7, 3, 8, 3, 9, 8, 7, 2, 0, 7, 5, 9, 3, 9, 7, 1, 8, 6, 4, 3, 6,\n",
              "       5, 0, 0, 1, 6, 9, 4, 8, 9, 4, 8, 1, 5, 3, 0, 5, 2, 2, 1, 7, 1, 3,\n",
              "       9, 3, 7, 2, 7, 6, 1, 1, 7, 5, 5, 1, 5, 8, 4, 0, 4, 0, 4, 5, 4, 1,\n",
              "       8, 1, 1, 5, 4, 0, 9, 8, 6, 7, 3, 3, 8, 3, 1, 6, 4, 6, 0, 1, 3, 6,\n",
              "       8, 6, 1, 1, 5, 8, 5, 1, 1, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOphf8EgQMEo",
        "outputId": "4db5ab63-a86a-4feb-c19c-195709a2e671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   7,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   1,  28,  56,  23,   0,\n",
              "         0,  56, 123, 184, 107,   0,  63, 177, 249,  96,   0,   0,   0,\n",
              "         0,   0,   0,   0,  47, 137, 149,  26,   0,   0, 141, 255, 255,\n",
              "       246,  39,  77, 255, 252, 226, 253,  25, 210, 233, 132,  19,   0,\n",
              "         0,  42, 161, 188,  49,   0, 154, 253, 255,  97,   0,   0, 218,\n",
              "       192, 101, 255,  78,  93, 255,  39,  83, 255, 105, 231, 163,   0,\n",
              "         0,   0,   0,  74, 213, 239, 180,   0, 165, 215, 254, 166, 105,\n",
              "       127, 255, 105,  26, 255, 136, 125, 255,  74,  83, 255, 255, 246,\n",
              "       108,   0,   0,   0,   0,   0,   0, 163, 238, 194, 248, 196, 226,\n",
              "       255, 255, 255, 220,  28,   7, 250, 255, 255, 255, 125,  74, 255,\n",
              "       115,   6,   0,   0,   0,   0,   0,   0,   0, 141, 248, 194, 129,\n",
              "        41,  18,  31,  16,   0,   0,   0,   0,  43,  60,  51,  47,   5,\n",
              "         1,  44,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   7,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb70CbLVyK65"
      },
      "source": [
        "## Build Your Baseline Model\n",
        "Some Hints:\n",
        "\n",
        "\n",
        "*  Model should have 784 input values (like mnist)\n",
        "*  Use `sparse_categorical_crossentropy` as your loss function.\n",
        "* You need 10 neurons in your last layer for output\n",
        "* You can add as many hidden layers with as many neurons in them as you like. \n",
        "* Limit your model epochs to 30 each time you fit.\n",
        "* You can use the `validation_split` command to automatically create a training / validation dataset.  Specify a percentage such as .2 in your fit statement. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc_gnsApQLKv",
        "outputId": "97e29702-7db7-40ac-9196-b996ab5f54c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Normalize the input\n",
        "X = X.astype('float32') / 255\n",
        "X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.02745098, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.00392157, 0.10980392, 0.21960784, 0.09019608, 0.        ,\n",
              "       0.        , 0.21960784, 0.48235294, 0.72156864, 0.41960785,\n",
              "       0.        , 0.24705882, 0.69411767, 0.9764706 , 0.3764706 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.18431373, 0.5372549 , 0.58431375,\n",
              "       0.10196079, 0.        , 0.        , 0.5529412 , 1.        ,\n",
              "       1.        , 0.9647059 , 0.15294118, 0.3019608 , 1.        ,\n",
              "       0.9882353 , 0.8862745 , 0.99215686, 0.09803922, 0.8235294 ,\n",
              "       0.9137255 , 0.5176471 , 0.07450981, 0.        , 0.        ,\n",
              "       0.16470589, 0.6313726 , 0.7372549 , 0.19215687, 0.        ,\n",
              "       0.6039216 , 0.99215686, 1.        , 0.38039216, 0.        ,\n",
              "       0.        , 0.85490197, 0.7529412 , 0.39607844, 1.        ,\n",
              "       0.30588236, 0.3647059 , 1.        , 0.15294118, 0.3254902 ,\n",
              "       1.        , 0.4117647 , 0.90588236, 0.6392157 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.2901961 , 0.8352941 ,\n",
              "       0.9372549 , 0.7058824 , 0.        , 0.64705884, 0.84313726,\n",
              "       0.99607843, 0.6509804 , 0.4117647 , 0.49803922, 1.        ,\n",
              "       0.4117647 , 0.10196079, 1.        , 0.53333336, 0.49019608,\n",
              "       1.        , 0.2901961 , 0.3254902 , 1.        , 1.        ,\n",
              "       0.9647059 , 0.42352942, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.6392157 , 0.93333334,\n",
              "       0.7607843 , 0.972549  , 0.76862746, 0.8862745 , 1.        ,\n",
              "       1.        , 1.        , 0.8627451 , 0.10980392, 0.02745098,\n",
              "       0.98039216, 1.        , 1.        , 1.        , 0.49019608,\n",
              "       0.2901961 , 1.        , 0.4509804 , 0.02352941, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.5529412 , 0.972549  , 0.7607843 , 0.5058824 ,\n",
              "       0.16078432, 0.07058824, 0.12156863, 0.0627451 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.16862746, 0.23529412,\n",
              "       0.2       , 0.18431373, 0.01960784, 0.00392157, 0.17254902,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
              "       0.02745098, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHWblzsMyNkU",
        "outputId": "4eead5b0-517e-47ce-9b91-8e550870e9cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# define architecture\n",
        "model = Sequential([\n",
        "  Dense(512, activation='relu', input_dim=784),\n",
        "  Dense(256, activation='relu'),\n",
        "  Dense(128, activation='relu'),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 575,050\n",
            "Trainable params: 575,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxLk_0_NQAJn",
        "outputId": "0d79f6fa-6d5f-4df0-c5e8-4d7a43b65bb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# fit on training / evaluate on validation set\n",
        "model.fit(X, y,\n",
        "          epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.6072 - accuracy: 0.8131 - val_loss: 0.4931 - val_accuracy: 0.8507\n",
            "Epoch 2/10\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.4227 - accuracy: 0.8720 - val_loss: 0.4777 - val_accuracy: 0.8595\n",
            "Epoch 3/10\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.3550 - accuracy: 0.8920 - val_loss: 0.4258 - val_accuracy: 0.8753\n",
            "Epoch 4/10\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.3048 - accuracy: 0.9063 - val_loss: 0.4258 - val_accuracy: 0.8784\n",
            "Epoch 5/10\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.2664 - accuracy: 0.9177 - val_loss: 0.4242 - val_accuracy: 0.8820\n",
            "Epoch 6/10\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.2317 - accuracy: 0.9282 - val_loss: 0.4634 - val_accuracy: 0.8825\n",
            "Epoch 7/10\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.2058 - accuracy: 0.9357 - val_loss: 0.4644 - val_accuracy: 0.8781\n",
            "Epoch 8/10\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1848 - accuracy: 0.9417 - val_loss: 0.4827 - val_accuracy: 0.8768\n",
            "Epoch 9/10\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1616 - accuracy: 0.9489 - val_loss: 0.5054 - val_accuracy: 0.8816\n",
            "Epoch 10/10\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1461 - accuracy: 0.9537 - val_loss: 0.5704 - val_accuracy: 0.8754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbc4af346d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj830L68NSkk",
        "outputId": "e7ba8ba5-98f7-4840-8c56-b0b7286622a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# evaluate on test data\n",
        "model.evaluate(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3125/3125 [==============================] - 5s 2ms/step - loss: 0.2111 - accuracy: 0.9447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2110884189605713, 0.9446799755096436]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0QJURWh-9uv"
      },
      "source": [
        "### Visualize the results\n",
        "\n",
        "Create charts for both loss and accuracy by epoch. Use line graphs for both charts. Analyze the results. \n",
        "\n",
        "At what point should we have stopped training the model and why? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KONJtU5wqlXf",
        "outputId": "befbb7bb-d640-4daf-ed15-c02ed5485379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "baseline.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c24739625ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'baseline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijAlzfYKAFaY",
        "outputId": "5d8d37b7-056f-4418-b9de-836419a1fd03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame.from_records(baseline.history)\n",
        "df['epoch'] = [i for i in range(df.shape[0])]\n",
        "\n",
        "ax = sns.lineplot(x='epoch', y='val_loss', data=df)\n",
        "ax = sns.lineplot(x='epoch', y='loss', data=df);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-205dbc7bcc16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'baseline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAhBrcE4yOZe"
      },
      "source": [
        "## Change Optimizers\n",
        "Try using the keras `adam` optimizer instead of `sgd` in your model. Visualize the difference in validation loss between the models with different optimizers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIW_spOZ0cxy"
      },
      "source": [
        "from tf.keras.optimizers import Adam\n",
        "\n",
        "adam = Adam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJrbh3qryi4w"
      },
      "source": [
        "### Additional Written Tasks:\n",
        "In this section, you will need to search for resources: \n",
        "1. Investigate the various [loss functions](https://www.tensorflow.org/api_docs/python/tf/keras/losses). Which is best suited for the task at hand (predicting 1 / 0) and why? \n",
        "2. What is the difference between a loss function and a metric? Why might we need both in Keras? \n",
        "3. Investigate the various [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). Stochastic Gradient Descent (`sgd`) is not the learning algorithm dejour anyone. Why is that? What do newer optimizers such as `adam` have to offer? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzs4fd-RynDd"
      },
      "source": [
        "## Stretch Goals: \n",
        "\n",
        "- Research convolutional neural networks and try including convolution layers in your network.\n",
        "- Pick two classes and make QuickDraw a binary classification problem, how does your model architecture change?\n",
        "- Implement Cross Validation model evaluation on your Quickdraw implementation \n",
        "\n",
        "Watch some more videos on Gradient Descent:\n",
        "- [Gradient Descent, Step-by-Step](https://www.youtube.com/watch?v=sDv4f4s2SB8)  by StatQuest w/ Josh Starmer. This will help you understand the gradient descent based optimization that happens underneath the hood of neural networks. It uses a non-neural network example, which I believe is a gentler introduction. You will hear me refer to this technique as \"vanilla\" gradient descent. \n",
        "- [Stochastic Gradient Descent, Clearly Explained!!!](https://www.youtube.com/watch?v=vMh0zPT0tLI) by StatQuest w/ Josh Starmer. This builds on the techniques in the previous video.  This technique is the one that is actually implemented inside modern 'nets. \n",
        "- [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)"
      ]
    }
  ]
}